
\section{Motivation}
\label{sec:motivation}

In this section, we will highlight the principal distinctive features of our approach \FAMA with respect to the related work reviewed in Section~\ref{related_work}.

\vspace{0.1cm}

%\subsection{Learning action models from plan traces of unbound horizon}
When learning action models from observations of plan executions there are two main sources of partial observability:
\begin{enumerate}
\item As many of the approaches in Section~\ref{sec:background} assume, there may be an unknown number of missing intermediate states in the trace because of the partial state observability (\PO and \NO). The assumption of having \FO state trajectories means that the sensors are able to capture every state change at every instant, which typically is unrealistic. Normally, the process for obtaining state feedback from sensors (or the processing of the sensor readings) is associated with a given sampling frequency that misses intermediate data between two subsequent sensor readings.

\item There may be also an unbound number of missing actions in the plan trace because of partial observability. The common assumption of having \FO action sequences in a learning task is unrealistic in many domains as it implies the existence of human observers that annotate the observed action sequences. In some real-world applications, the observed and collected data are sensory data (e.g., home automation, robotics) or images (e.g. traffic) and one cannot rely on human intervention for labeling actions. Actually, learning the executed actions can also be part of the action-model learning task. Learning, for instance, from unstructured data involves transforming the sensor or image information into a predicate-like format before applying the action-model learning approach, and it also requires the ability of identifying action symbols~\cite{AsaiF18}.
\end{enumerate}


\FAMA represents one step ahead towards learning action models without assuming observed actions. The main novelty of \FAMA with respect to other approaches lies in that our system is capable of handling \PO and \NO action sequences, which combined with \PO and \NO state trajectories, make the learning task more challenging. This essentially brings one key difference: the transition between two given observed states may now involve more than one action; i.e., $\theta(s_i,\tup{a_1,\ldots,a_k})=s_{i+1}$, with $k \geq 1$, $k$ unknown and unbound, and so the horizon of the input plan traces is no longer known now. Table \ref{tab:complex} shows that the worst case complexity of learning \strips\ action models becomes PSPACE-complete when combining \PO and \NO state trajectories and action sequences.

In this particular scenario, the actual number of plan traces associated to a given input observation is also unbound and grows exponentially with the actual length of the plan trace (that is now unknown). Otherwise, the learning task is SAT compilable, which is known to be a NP-complete task~\cite{russell2016artificial}. This is the reason that SAT solving is a common technique in the approaches presented in section \ref{sec:background}.


\begin{table}[ht]
\centering
\begin{tabular}{c|c|c|c|c|}
	& \multicolumn{4}{c|}{\emph{state observability}} \\ \cline{2-5}
	\multirow{1}{*}{\emph{action}} & \FO & \POstar & \PO & \NO\\ {\emph{observability}} & & & & \\ \hline
	\FO & - & NP-complete & NP-complete & NP-complete \\ \hline
	\PO & NP-complete & NP-complete & \textbf{PSPACE-complete} & \textbf{PSPACE-complete} \\ \hline
	\NO & NP-complete & NP-complete & \textbf{PSPACE-complete} & \textbf{PSPACE-complete} \\ \hline
\end{tabular}
\caption{Complexity of learning tasks according to the type of input trace}
\label{tab:complex}
\end{table}


When we assume partial observability in both actions and states, a complete approach must consider the length of the input plan traces to be unknown. \FAMA shows that classical planning is a complete approach for this particular scenario. Consequently, the new learning scenario features PSPACE-complete instead of NP-complete tasks, which motivates and justifies the use of planning, as our proposal of compiling the learning task to a classical planning problem.

When the plan trace is fully observed, learning \strips\ action models is straightforward~\cite{jimenez2012review}. In this case the {\em pre-} and {\em post-states} of every action are available and so action {\em effects} are derived lifting the literals that change between the pre and post-state of the corresponding action executions. Likewise {\em preconditions} are derived lifting the minimal set of literals that appears in all the pre-states of the corresponding action.


%In \FAMA we set a probability threshold of observability to each fluent and action, which determines the percentage of literals in each state and in turn the percentage of observed states (when the probability of every fluent is above the threshold, the result is a missing state). This way, \FAMA must always work under the assumption that the number and length of the input plan traces are unknown and so the task of learning an action model becomes as hard as solving a \strips planning problem. Consequently, the new learning scenario features PSPACE-complete instead of NP-complete tasks, which motivates and justifies the use of planning techniques, as our proposal of compiling the learning task to a planning problem.

%Thereby, solving this type of learning tasks justifies the use of techniques other than SAT solvers, as our proposal of compiling the learning task to a planning problem.


\vspace{0.1cm}
Regarding the evaluation of the learned action models, we can observe in Table \ref{table:models_comparison2} that most of the approaches use a similar syntax-based metric that consists in (1) counting the missing and extra fluents that appear in the learned model wrt the GTM and (2) normalizing this error by the the total number of all the possible preconditions and effects of an action model. This is an \emph{optimistic} metric since error rates are not normalized by the size of the actual GTM. The set of preconditions and effects of the GTM is usually smaller than the set of all possible preconditions and effects and thereby it turns out that these syntax-based metrics may output error rates below 100\% for totally wrong learned models. To overcome this limitation we propose to use two standard metrics from ML, {\em precision} and {\em recall}, that are frequently used in pattern recognition, information retrieval and binary classification~\cite{davis2006relationship}. %{\em Precision} and {\em recall} are more informative that simply counting the number of errors in the learned model or computing the {\em symmetric difference} between the learned and the reference model.

Pure syntax-based evaluation metrics, like the ones mentioned in the above paragraph, can report low scores for learned models that are actually {\em sound} and {\em complete} but syntactically different from the GTM. Semantic evaluation metrics add a distinctive value over the syntactic ones, which is that they evaluate the learned model with a set of observations of plan executions and hence they are appropriate for scenarios where the GTM is not available. In this sense, \FAMA also contributes with a novel semantic-based error measure that builds upon the {\em precision} and {\em recall} metrics. Unlike the semantic metric used in \ARMS~\cite{yang2007learning}, our semantic version of {\em precision} and {\em recall} is not sensitive to the repetition of one same flaw in the model evaluation.


%When learning action models from observations of plan executions, the roles of two {\em comparable} action schemes (or the roles of two action parameters with the same type) can be swapped. These role swaps typically happen when the observed input data is scarce. For instance the {\em blocksworld} operator {\small\tt stack} can be {\em learned} with the preconditions and effects of the {\small\tt unstack} operator and vice versa. Further, the roles of parameters of the {\small\tt stack} (or the {\small\tt unstack}) operator could be swapped and these learned models would still be semantically correct with respect to the given input observations.

%Pure syntax-based evaluation metrics can report low scores for learned models that are actually {\em sound} and {\em complete} but correspond to {\em reformulations} of the GTM model; i.e. a learned model semantically equivalent but syntactically different to the reference model. The ARMS system implemented semantic metrics for evaluating the learned action models with respect to observations of plan executions that act as a {\em test set}. This semantic evaluation approach is suitable for scenarios where the GTM is not available, e.g. the traditional ML setting. For this scenario our work proposes semantic versions of {\em precision} and {\em recall} that provide a notion of the soundness and completeness of the learned models with respect to input plan traces. Unlike the metrics defined by ARMS, our semantic metrics do not accumulate errors that are caused by the same flaw in the learned model.

%\subsection{Input data}

On the other hand, a striking figure of Table \ref{table:models_comparison2} that emphasizes a relevant feature of \FAMA is the small size of the training dataset it requires in comparison to other approaches. Unlike extensive-data ML approaches, our work explores an alternative research direction to learn sound models from small amounts of plan traces. This is an important advantage, particularly in domains in which it is costly or impossible to obtain a significant number of training samples. Unlike \CAMA, our approach does not require human intervention to label samples as it is able to learn from very small datasets.

Finally, as it will be shown in section \ref{sec:experiments}, \FAMA is exhaustively evaluated, syntactically and semantically, over a wide range of domains (13 domains compared to the scarce number of tested domains of the rest of the approaches in Table \ref{table:models_comparison2}) and uses exclusively an \emph{off-the shelf} classical planner so it can benefit straightforward from the last advances in classical planning.


























