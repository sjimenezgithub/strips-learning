\section{Motivation}
\label{sec:motivation}

The main novelty of \FAMA with respect to other approaches lies in that our system is capable of handling input plan traces whose length is a priori unbound. This brings one essential difference:
\begin{itemize}
\item The transition between two given observed states may now involve the execution of more than a single action. Formally $\theta(s_i,\tup{a_1,\ldots,a_k})=s_{i+1}$, where $k\geq 1$ is unkown and unbound; 
\end{itemize}

In this particular scenario the number of actual plan traces that can correspond with the given input observations is also unbound and grows exponentially with the actual length of the plan trace (that is now unknown). Otherwise, the learning task is SAT compilable, which is known to be a NP-complete task~\cite{russell2016artificial}. This is the reason that SAT solving is a common technique in the approaches presented in section \ref{sec:background}.

Under this new assumption, the learning of \strips\ action models that satisfy a set of observations of plan executions becomes PSPACE-complete instead of NP-complete, which motivates planning as a more  suitable approach for the learning of \strips\ action models. The length a plan trace, that represent the observation of a plan execution, is a priori unbound because of the conjunction of the following two causes:
\begin{enumerate}
\item There may be an unbound number of missing intermediate states in the trace because of partial state observability. The assumption of having \FO state trajectory means that the sensors are able to capture every state change at every instant which typically is unrealistic. Normally the process of getting state feedback from sensors (or the processing of the sensor readings) is associated with a given sampling frequency that misses intermediate data between two sensor readings.

\item There may be an unbound number of missing intermediate actions in the trace because of partial observability. The common assumption of having \FO action sequences in a learning task is rather unrealistic in many domains because it implies the existence of human observers that annotate the observed action sequences. In some real-world applications, the observed and collected data are sensory data (e.g., home automation, robotics) or images (e.g. traffic) and one cannot rely on human intervention for labeling actions. Actually, learning the executed actions can also be part of the action-model learning task. Learning from unstructured data involves some prior processing to transform the sensor or image information into a predicate-like format before applying the action-model learning approach~\cite{AsaiF18}, and it also requires the ability of identifying action symbols. In this sense, this work represents a step ahead towards learning action models without assuming observed actions.
\end{enumerate}

The Table~\ref{tab:complex} precisely characterizes the scenarios where the length of the input plan traces cannot longer be assumed to be unbound.
\begin{table}[ht]
\centering
\begin{tabular}{c|c|c|c|c|}
	& \multicolumn{4}{c|}{\emph{state observability}} \\ \cline{2-5}
	\multirow{1}{*}{\emph{action}} & \FO & \PO & \POstar & \NO\\ {\emph{observability}} & & & & \\ \hline
	\FO & NP-complete & NP-complete & NP-complete & NP-complete \\ \hline
	\PO & NP-complete & PSPACE-complete & PSPACE-complete & PSPACE-complete \\ \hline
	\NO & NP-complete & PSPACE-complete & PSPACE-complete & PSPACE-complete\\ \hline
\end{tabular}
\caption{Complexity of learning tasks according to the kinf of the input plan traces.}
\label{tab:complex}
\end{table}



    
Regarding the metric to evaluate the learned action models, we can observe in Table \ref{table:models_comparison2} that most of the approaches use a similar metric that consists in counting the missing and extra fluents that appear in the learned model wrt the GTM and normalizing by the the total number of all the possible preconditions and effects of an action model. This is an {\em optimistic} metric since it returns error rates that are not normalized with respect to the size of the actual models. For intance these metrics it could output a rate below 100\% for a totally wrong learned model that only includes a subset of all possible preconditions and effects of an action model.

To overcome this limitation, we propose to use two standard ML metrics, {\em precision} and {\em recall}. These two metrics are frequently used in {\em pattern recognition}, {\em information retrieval} and {\em binary classification} and are more informative that simply counting the number of errors in the learned model or computing the {\em symmetric difference} between the learned and the reference model~\cite{davis2006relationship}.

A striking figure of Table \ref{table:models_comparison2} that emphasizes a relevant feature of \FAMA is the small size of the training dataset it requires in comparison to other approaches. Unlike extensive-data ML approaches, our work explores an alternative research direction to learn sound models from small amounts of plan traces. This is an important advantage, particularly in domains in which it is costly or impossible to obtain a significant number of training samples. Unlike \CAMA, our approach does not require human intervention to label samples as it is able to learn from very small datasets.

Finally, we would also like to point out that, as shown in section \ref{experiments}, \FAMA is exhaustively evaluated over a wide range of domains (15 domains compared to the scarce number of tested domains of the rest of the approaches in Table \ref{table:models_comparison2}) and uses exclusively an \emph{off-the shelf} classical planner.


  
%We set a probability threshold of observability to each fluent and action, which determines the percentage of literals in each state and in turn the percentage of observed states (when the probability of every fluent is above the threshold, the result is a missing state). This way, \FAMA must always work under the assumption that the length of the input plan traces is unknown.































