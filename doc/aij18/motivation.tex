
\section{Motivation}
\label{sec:motivation}

The main novelty of \FAMA with respect to other approaches lies in that our system is capable of handling \PO and \NO action sequences, which combined with \PO and \NO state trajectories, make the learning task more challenging. This essentially brings one key difference: the transition between two given observed states may now involve more than one action; i.e., $\theta(s_i,\tup{a_1,\ldots,a_k})=s_{i+1}$, with $k \geq 1$, $k$ unknown and unbound, and so the horizon of the input plan traces is no longer known now.

In this particular scenario, the actual number of plan traces that can correspond with the given input observations is also unbound and grows exponentially with the actual length of the plan trace (that is now unknown). Otherwise, the learning task is SAT compilable, which is known to be a NP-complete task~\cite{russell2016artificial}. This is the reason that SAT solving is a common technique in the approaches presented in section \ref{sec:background}.

When we assume partial observability in both the sequence of actions and the state trajectory, a complete approach must consider the length of the input plan traces to be unknown. This work shows that classical planning is a complete approach for this particular scenario. Consequently, the new learning scenario features PSPACE-complete instead of NP-complete tasks, which motivates and justifies the use of planning techniques, as our proposal of compiling the learning task to a planning problem.

When the plan trace is fully observed, learning \strips\ action models is straightforward~\cite{jimenez2012review}. In this case the {\em pre-} and {\em post-states} of every action are available so action {\em effects} are derived lifting the literals that change between the pre and post-state of the corresponding action executions. Likewise {\em preconditions} are derived lifting the minimal set of literals that appears in all the pre-states of the corresponding action.


%In \FAMA we set a probability threshold of observability to each fluent and action, which determines the percentage of literals in each state and in turn the percentage of observed states (when the probability of every fluent is above the threshold, the result is a missing state). This way, \FAMA must always work under the assumption that the number and length of the input plan traces are unknown and so the task of learning an action model becomes as hard as solving a \strips planning problem. Consequently, the new learning scenario features PSPACE-complete instead of NP-complete tasks, which motivates and justifies the use of planning techniques, as our proposal of compiling the learning task to a planning problem.

%Thereby, solving this type of learning tasks justifies the use of techniques other than SAT solvers, as our proposal of compiling the learning task to a planning problem.


\begin{table}[ht]
\centering
\begin{tabular}{c|c|c|c|c|}
	& \multicolumn{4}{c|}{\emph{state observability}} \\ \cline{2-5}
	\multirow{1}{*}{\emph{action}} & \FO & \POstar & \PO & \NO\\ {\emph{observability}} & & & & \\ \hline
	\FO & - & NP-complete & NP-complete & NP-complete \\ \hline
	\PO & NP-complete & NP-complete & \textbf{PSPACE-complete} & \textbf{PSPACE-complete} \\ \hline
	\NO & NP-complete & NP-complete & \textbf{PSPACE-complete} & \textbf{PSPACE-complete} \\ \hline
\end{tabular}
\caption{Complexity of learning tasks according to the type of input trace}
\label{tab:complex}
\end{table}


Table \ref{tab:complex} displays the complexity of the learning task according to the type of input trace. The PSPACE-complexity happens when the length of the plan trace is a priori unbound, which results from the combination of the following two causes:

\begin{enumerate}
\item As many of the approaches in section \ref{sec:background} assume, there may be an unknown number of missing intermediate states in the trace because of partial state observability (\PO and \NO). The assumption of having \FO state trajectory means that the sensors are able to capture every state change at every instant which typically is unrealistic. Normally the process of getting state feedback from sensors (or the processing of the sensor readings) is associated with a given sampling frequency that misses intermediate data between two sensor readings.

\item There may be also an unbound number of missing actions in the plan trace because of partial observability. The common assumption of having \FO action sequences in a learning task is unrealistic in many domains because it implies the existence of human observers that annotate the observed action sequences. In some real-world applications, the observed and collected data are sensory data (e.g., home automation, robotics) or images (e.g. traffic) and one cannot rely on human intervention for labeling actions. Actually, learning the executed actions can also be part of the action-model learning task. Learning from unstructured data involves some prior processing to transform the sensor or image information into a predicate-like format before applying the action-model learning approach~\cite{AsaiF18}, and it also requires the ability of identifying action symbols. In this sense, \FAMA represents a step ahead towards learning action models without assuming observed actions.
\end{enumerate}


Regarding the metric to evaluate the learned action models, we can observe in Table \ref{table:models_comparison2} that most of the approaches use a similar metric that consists in (1) counting the missing and extra fluents that appear in the learned model wrt the GTM and (2), normalizing this error by the the total number of all the possible preconditions and effects of an action model. This is an \emph{optimistic} metric since error rates are not normalized by the size of the actual GTM model. Hence, because the set of preconditions and effects of the GTM model is usually smaller than the set of all possible preconditions and effects, it turns out the metric may output error rates below 100\% for totally wrong learned models.


In order to overcome this limitation, we propose to use two standard metrics from ML, {\em precision} and {\em recall}. These two metrics are frequently used in pattern recognition, information retrieval and binary classification and are more informative that simply counting the number of errors in the learned model or computing the {\em symmetric difference} between the learned and the reference model~\cite{davis2006relationship}.

A striking figure of Table \ref{table:models_comparison2} that emphasizes a relevant feature of \FAMA is the small size of the training dataset it requires in comparison to other approaches. Unlike extensive-data ML approaches, our work explores an alternative research direction to learn sound models from small amounts of plan traces. This is an important advantage, particularly in domains in which it is costly or impossible to obtain a significant number of training samples. Unlike \CAMA, our approach does not require human intervention to label samples as it is able to learn from very small datasets.

Finally, we would also like to point out that, as shown in section \ref{experiments}, \FAMA is exhaustively evaluated over a wide range of domains (15 domains compared to the scarce number of tested domains of the rest of the approaches in Table \ref{table:models_comparison2}) and uses exclusively an \emph{off-the shelf} classical planner so it can benefit straightforward from the last advances in classical planning.




























