
\section{Evaluation of action models}
\label{sec:evaluation}

In this section we introduce the metrics used by \FAMA to evaluate the action models that result from solving a learning task $\Lambda$. First, we will motivate the use of two standard syntactic metrics ({\em precision} and {\em recall}). Then, section \ref{syntactic_precision_recall} will define these metrics for planning models, and section \ref{semantic_precision_recall} will introduce a semantic evaluation measure that builds upon {\em precision} and {\em recall}. Finally, section \ref{edit_distance} explains how \FAMA computes our novel semantic-based metrics.


We can observe in Table \ref{table:models_comparison2} that most of the approaches use a similar syntax-based metric that consists in (1) counting the missing and extra fluents that appear in the learned model wrt the GTM and (2) normalizing this error by the the total number of all the possible preconditions and effects of an action model. This is an \emph{optimistic} metric since error rates are not normalized by the size of the actual GTM. The set of preconditions and effects of the GTM is usually smaller than the set of all possible preconditions and effects and thereby it turns out that these syntax-based metrics may output error rates below 100\% for totally wrong learned models. To overcome this limitation we propose to use two standard metrics from ML, {\em precision} and {\em recall}, that are frequently used in pattern recognition, information retrieval and binary classification~\cite{davis2006relationship}. These two syntactic metrics are generally more informative than counting the number of errors between the learned action models and the GTM:


\begin{itemize}
\item $Precision=\frac{tp}{tp+fp}$, where $tp$ is the number of {\em true positives} (in our particular case, predicates that correctly appear in the action model) and $fp$ is the number of {\em false positives} (predicates of the learned model that should not appear).
\item $Recall=\frac{tp}{tp+fn}$, where $fn$ is the number of {\em false negatives} (predicates that should appear in the learned model but are missing).
\end{itemize}

\subsection{Syntactic-based precision and recall for planning models}
\label{syntactic_precision_recall}

The rationale behind the adaptation of precision and recall for planning models lies in counting the \emph{edit operations} that need to be applied in domain model $\mathcal{M}$ to transform it into the reference model $\mathcal{M'}$. Given a domain model $\mathcal{M}$, the two allowed edit operations are:

\begin{itemize}
	\item {\em Deletion}. A fluent $pre_p(\xi)/del_p(\xi)/add_p(\xi)$ is removable from $\xi\in\mathcal{M}$.
	\item {\em Insertion}. A fluent $pre_p(\xi)/del_p(\xi)/add_p(\xi)$ can be added to $\xi\in\mathcal{M}$.
\end{itemize}

We now provide formal definitions of $INS(\mathcal{M},\mathcal{M'})$ and $DEL(\mathcal{M},\mathcal{M'})$, the sets of insertions and deletions, respectively, that are needed to transform a domain model $\mathcal{M}$ into a new domain model $\mathcal{M'}$.

\begin{mydefinition}
	Let $PRE(\xi) = \underset{p \in pre(\xi)}{\bigcup} pre_p(\xi)$, $ADD(\xi) = \underset{p \in add(\xi)}{\bigcup} add_p(\xi)$, and $DEL(\xi) = \underset{p \in del(\xi)}{\bigcup} del_p(\xi)$ be the set of propositional fluents that represent preconditions, positive and negative effects of a given action model $\xi$. We define:
	\begin{small}
		
			\begin{align*}
			INS(\mathcal{M}, \mathcal{M'})=&\bigcup\limits_{\xi\in\mathcal{M}, \xi'\in\mathcal{M'} s.t.\ name(\xi) = name(\xi')}
			PRE(\xi') \backslash PRE(\xi) \cup
			ADD(\xi') \backslash ADD(\xi) \cup
			DEL(\xi') \backslash DEL(\xi)
			\\
			\\
			DEL(\mathcal{M}, \mathcal{M'})=&\bigcup\limits_{\xi\in\mathcal{M}, \xi'\in\mathcal{M'} s.t.\ name(\xi) = name(\xi')}
			PRE(\xi) \backslash PRE(\xi') \cup
			ADD(\xi) \backslash ADD(\xi') \cup
			DEL(\xi) \backslash DEL(\xi')
			\end{align*}
		
	\end{small}
\end{mydefinition}


With these ingredients in mind, we adapt the definitions of syntactic precision and recall to domain models. Let $\mathcal{M}$ be a domain model and let $\mathcal{M'}$ be the GTM. We know that $size(\mathcal{M}) = \sum_{\xi \in \mathcal{M}}\left|pre(\xi)\right| + \left|add(\xi)\right| + \left|del(\xi)\right|$ and by definition the number of preconditions and effects of the learned action models is equal to the sum of {\em true positives} and {\em false positives}; that is, $size(\mathcal{M}) = tp + fp$.

The number of \emph{deletions} required to transform $\mathcal{M}$ into $\mathcal{M'}$ ($\left|DEL(\mathcal{M},\mathcal{M'})\right|$) matches our previous definition of the number of {\em false positives}; and $\left|INS(\mathcal{M},\mathcal{M'})\right|$, the number of \emph{insertions} required to transform $\mathcal{M}$ into $\mathcal{M'}$, corresponds to the number of {\em false negatives} of $\mathcal{M}$. Then we can affirm that $size(\mathcal{M'}) = size(\mathcal{M}) - \left|DEL(\mathcal{M},\mathcal{M'})\right| + \left|INS(\mathcal{M},\mathcal{M'})\right|$.

\begin{mydefinition} \label{syn-precision} The precision of $\mathcal{M}$ relative to the GTM is defined as the fraction of the common preconditions and effects between $\mathcal{M}$ and the GTM among all prediconditions and effects of $\mathcal{M}$.
	\begin{small}
		\begin{align*}
		Precision=\frac{tp}{tp+fp}=\frac{size(\mathcal{M})- \left|DEL(\mathcal{M},GTM)\right|}{size(\mathcal{M})}
		\end{align*}
	\end{small}
\end{mydefinition}



\begin{mydefinition} \label{syn-recall} The recall of $\mathcal{M}$ relative to the GTM is defined as the fraction of the common preconditions and effects between $\mathcal{M}$ and the GTM among all preconditions and effects of the GTM.
	
	\begin{small}
		\begin{align*}
		Recall= \frac{tp}{tp+fn}=
		\frac{size(\mathcal{M})- \left|DEL(\mathcal{M},GTM)\right|}{size(\mathcal{M}) - \left|DEL(\mathcal{M},GTM)\right| + \left|INS(\mathcal{M},GTM)\right|}
		\end{align*}
	\end{small}
\end{mydefinition}

Intuitively, precision gives a notion of {\em soundness} while recall gives a notion of the {\em completeness} of the learned models. We interpret a sound learned model as one in which all preconditions and effects are correct with respect to the GTM, and so there is no need to remove anything. A complete model is one in which no precondition or effect is missing.
As an example, a precision of 0.5 means that only half of the predicates that make up the learned domain model are present in the GTM, while a recall of 0.5 means that only half of the predicates that make up the GTM are present in the learned domain model.

\subsection{Semantic-based precision and recall for planning models}
\label{semantic_precision_recall}

Pure syntax-based evaluation metrics can report low scores for learned models that are actually {\em sound} and {\em complete} but syntactically different from the GTM. Semantic evaluation metrics add a distinctive value over the syntactic ones, which is that they evaluate the learned model with a set of observations of plan executions. These metrics measure how well a model can reproduce a given plan execution, so the use of the word "semantic" here is in reference to the degree to which the learned model is able to capture the physics of the domain. Semantic metrics are appropriate for scenarios where:

\begin{enumerate}
	\item The GTM is unknown. This is the most common scenario in ML, where models are both learned and evaluated with respect to datasets.
	\item We are interested in measuring the ability of a model to explain a given plan trace, which is a good indicator of how the model will perform in actual planning tasks. As a rule of thumb, it is preferable to evaluate the learned models wrt a dataset because a learned model can be semantically correct though syntactically incorrect (different from the GTM). We refer to this phenomenon as \emph{model reformulation}.
\end{enumerate}

An example of \emph{model reformulation} is the swapping of the roles of two {\em comparable} action models. Two action models $\xi$ and $\xi'$ are comparable if both have the same parameters (iff $pars(\xi)=pars(\xi'$)) and so they share the same space of possible models. Hence, the {\em blocksworld} operator {\small\tt stack} could be {\em learned} with the preconditions and effects of the {\small\tt unstack} operator, and viceversa, because they are comparable. On the contrary, this reformulation will not happen between the {\tt stack} and {\tt pickup} because they are not comparable. In the same way, the roles of two action parameters that share the same type can also be swapped (e.g., interchanging the role of the two parameters of the operator {\small\tt stack} or the opreator {\small\tt unstack}) and yet the learned models would be semantically correct with respect to the given input observations. A more complex kind of reformulation occurs when two or more action models are learned in a single \emph{macro-action}. These semantic alterations typically appear in the learned models when the observed input data given in $\tau$ is scarce.


The \ARMS system was the first to show that a semantic evaluation can be done via validation of a set of plan traces with the learned model~\cite{yang2007learning}. The underlying idea is that an error indication of the learned action models is obtained by counting the number of preconditions that are not satisfied during the execution of the plan trace with the learned models, similarly to the functionality provided by the automatic validation tool VAL~\cite{howey2004val} used in the IPCs. This approach can be understood as modifying the plan trace (by adding the necessary preconditions to the intermediate states) so as to allow the execution of the observed actions using the learned models. In other words, modifying the plan trace to fit the model. Inspired by this approach, we present novel semantic-based error measure that builds upon the {\em precision} and {\em recall} metrics, and instead, determines the modifications required by a learned model to explain the given plan traces.


We interpret the semantic evaluation of action models as a learning task $\Lambda = \tup{\mathcal{M}, \mathcal{T}}$, where:

\begin{itemize}
	\item $\mathcal{M}$ is a \textbf{learned domain model} obtained using any learning approach such as \FAMA; in general, $\mathcal{M}$ can be any given input domain model even manually encoded.
	\item$\mathcal{T}$ is a set of plan traces  used for \textbf{testing}.
\end{itemize}


A solution to this task is an \textbf{edited domain model} $\mathcal{M'}$ such that (1) $\mathcal{M'}$ is obtained by exclusively applying a finite sequence of \emph{deletion} and \emph{insertion} operations to $\mathcal{M}$ and (2) $\mathcal{M'}$ explains $\mathcal{T}$; i.e. $\mathcal{M'}$ is consistent with every plan trace $\tau\in\mathcal{T}$. It is always recommended for the test set to be different from the one used during learning and this is specially important for satisfying approaches such as \FAMA; otherwise $\mathcal{M'}$ = $\mathcal{M}$ since $\mathcal{M}$ would be able to explain $\mathcal{T}$ without any modification.

Since we are defining the semantic evaluation task in terms of a learning task $\Lambda$, there might exist potentially many edited models $\mathcal{M'}$ which are solution to this task. Although the actual GTM is included among the solution set, it is impossible to identify it, so we define the best solution based on its proximity to the input model.

\begin{mydefinition} \label{compliant}
  Given a domain model $\mathcal{M}$, and all the domain models $\mathcal{M'}$ able to explain the plan traces $\mathcal{T}$. The {\bf closest consistent domain model}, $\mathcal{M^*}$, is the comparable domain model closest to $\mathcal{M}$ (in terms of editions) that is able to explain $\mathcal{T}$;
  \[\mathcal{M^*}=\underset{\forall \mathcal{M}' \rightarrow \mathcal{T}}{\arg\min} \ \left| INS(\mathcal{M},\mathcal{M'}) \cup DEL(\mathcal{M},\mathcal{M'}) \right|\]
\end{mydefinition}


The closest consistent domain model $\mathcal{M^*}$ allows us to define a semantic version of {\em precision} and {\em recall} following definitions \ref{syn-precision} and \ref{syn-recall}.


\begin{small}
	\begin{align*}
	sem\text{-}Precision=&\frac{size(\mathcal{M})- \left|DEL(\mathcal{M},\mathcal{M^*})\right|}{size(\mathcal{M})}\\
    \vspace{0.5cm}
	sem\text{-}Recall=&\frac{size(\mathcal{M})- \left|DEL(\mathcal{M},\mathcal{M^*})\right|}{size(\mathcal{M}) - \left|DEL(\mathcal{M},\mathcal{M^*})\right| + \left|INS(\mathcal{M},\mathcal{M^*})\right|}
	\end{align*}
\end{small}


\begin{myproposition}
When the closest consistent domain model $\mathcal{M^*}$ of an evaluation task $\Lambda = \tup{\mathcal{M}, \mathcal{T}}$ is the GTM, the syntactic and semantic evaluation of $\mathcal{M}$ return the same values; that is, $Precision=sem\text{-}Precision$ and $Recall=sem\text{-}Recall$.
\end{myproposition}


The intuition behind this evaluation is to {\em semantically} assess how well the learned domain model $\mathcal{M}$ explains a set of given observations of plan executions according to the amount of {\em edition} required by $\mathcal{M}$ to induce the observations. The interpretation of a sound and complete model in the semantic perspective is slightly different from the syntactic one. In this case, a sound model is one were there is no need to remove any precondition or effect in order to be consistent with some given plan traces. A complete model is one that is consistent with the given plan traces without adding any of its preconditions and effects. Unlike the semantic metric defined by ARMS, our novel semantic definitions of precision and recall are not sensitive to flaws in the action model that manifest more than once in the plan traces since the flaws are corrected only once in the learned models instead of at every intermediate state of the plan traces.


\subsection{Semantic evaluation with classical planning}
\label{edit_distance}


The compilation scheme presented in section \ref{compilation} is extensible to address the evaluation task $\Lambda=\tup{\mathcal{M}, \mathcal{T}}$ defined in section \ref{semantic_precision_recall}. In this extended task, $\mathcal{M}$ represents a previously learned domain model; therefore, rather than learning the action models from scratch, we simply edit $\mathcal{M}$ until it satisfies the given test set of plan traces $\mathcal{T}$. A solution to the classical planning task resulting from the extended compilation is a plan that:

\begin{enumerate}
\item {\bf Edits the domain model $\mathcal{M}$ to build $\mathcal{M}'$}. A solution plan starts with a prefix that modifies the preconditions and effects of the action schemes in $\mathcal{M}$ using the two {\em edit operations} defined above, {\em deletion} and {\em insertion}.
\item {\bf Validates the edited model $\mathcal{M}'$ in the observed plan traces}. The solution plan continues with a postfix that validates the edited model $\mathcal{M}'$ on the given observations $\mathcal{T}$, as explained in Section~\ref{compilation} for the models that are programmed from scratch.
\end{enumerate}

Given $\Lambda=\tup{\mathcal{M},\mathcal{T}}$, the output of the extended compilation is a planning task $P_{\Lambda}'=\tup{F_{\Lambda},A_{\Lambda}',I_{\Lambda},G_{\Lambda}}$ such that:

\begin{itemize}
\item $F_{\Lambda}$, $I_{\Lambda}$ and $G_{\Lambda}$ are defined as in the previous compilation. Note that, the input action model $\mathcal{M}$ is encoded in the initial state. This means that the fluents $pre_p(\xi)/del_p(\xi)/add_p(\xi)$, $p\in \Psi_\xi$, hold in $I_{\Lambda}$ iff they appear in $\mathcal{M}$.
\item $A_{\Lambda}'$, comprises the same three kinds of actions of $A_{\Lambda}$. The actions for {\em applying} an already programmed action model and the actions for {\em validating} an observation are defined exactly as in the previous compilation. The only difference here is that the {\em programming actions} now implement the two editing operations (i.e., they also include the actions for {\em deleting} a precondition or negative/positive effect from an action model).
\end{itemize}

Figure~\ref{fig:plan-pdistance} shows the plan for editing the action model of the operator {\tt\small stack} of the {\em blocksworld} domain where only the two positive effects {\tt\small (handempty)} and {\tt\small (clear ?v1)} are missing. In this case the edited action model is again validated in the plan trace shown in Figure~\ref{fig:example-plans}.

\begin{figure}[hbt!]
{\footnotesize\tt
  {\bf 00} : (insert\_add\_stack\_handempty)\\
  01 : (insert\_add\_stack\_clear\_var1)\\
  {\bf 02} : (apply\_unstack blockB blockA i1 i2)\\
  03 : (apply\_putdown blockB i2 i3)\\
  04 : (apply\_pickup blockA i3 i4)\\
  05 : (apply\_stack blockA blockB i4 i5)\\
  {\bf 06} : (validate\_1)
}
\caption{\small Plan for editing and validating the action model {\tt\small{stack}} in which the positive effects {\tt\small{(handempty)}} and {\tt\small{(clear ?v1)}} are missing.}
\label{fig:plan-pdistance}
\end{figure}

Assuming we are using an optimal planner to solve $P_{\Lambda}'$, the solution plan of this problem will induce the \emph{closest consistent domain model} $\mathcal{M^*}$. Therefore, our compilation enables the straightforward computation of the semantic versions of \emph{precision} and \emph{recall}. An argument can be made, however, that solving optimally $P_{\Lambda}'$ may turn the evaluation process very time consuming. Considering this, $sem\text{-}Precision$ and $sem\text{-}Recall$ can be approximated if $P_{\Lambda}'$ is solved with a satisfying planner. In this case, no guarantees can be made that the edited model will be the closest consistent one, but a classical planner will always try to minimize the solution plan length and hence the number of edit operations applied to the input model.














