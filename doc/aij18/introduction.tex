
\section{Introduction}
\label{sec:introduction}

Besides {\em plan synthesis}~\cite{ghallab2004automated}, planning action models are also useful for {\em plan/goal recognition}~\cite{ramirez2012plan}. At both planning tasks, automated planners reason about action models that correctly and completely capture the possible world transitions~\cite{geffner:book:2013}. Unfortunately, modeling planning actions is complex, even for planning experts, and this knowledge acquisition task is a bottleneck that limits the potential of AI planning~\cite{kambhampati:modellite:AAAI2007}.

Machine Learning (ML) has shown to be able to compute a wide range of different kinds of models from examples~\cite{michalski2013machine}. The application of inductive ML to the learning of \strips\ action models, the vanilla action model for automated planning~\cite{fikes1971strips}, is not straightforward though:
\begin{itemize}
\item The {\em input} to ML algorithms (the {\em learning/training} data) usually are finite vectors encoding the value of fixed features in a given set of objects. The input for learning planning action models are observations of plan executions (where each observed plan possibly has a different number of steps and involves a different number of objects).
\item The {\em output} of ML algorithms usually is a scalar value (an integer, in the case of {\em classification} tasks, or a real value, in the case of {\em regression} tasks). When learning \strips\ action models the output is, for each action, the sets of {\em preconditions}, {\em negative} and {\em positive effects} that define the possible state transitions.
\end{itemize}

Motivated by recent advances on the synthesis of different kinds of generative models with classical planning~\cite{bonet2009automatic,segovia2016generalized,segovia2016hierarchical,segovia2017generating}, this paper introduces an innovative approach for learning \strips\ action models that can be defined as a classical planning compilation. A solution to the classical planning task that results from our compilation is a sequence of actions that determines the preconditions and effects of a \strips\ model such that this model satisfies the plan executions given as input.

The compilation approach is appealing by itself because it leverages off-the-shelf planners and because its practicality allow us to report learning results over a wide range of domains from the {\em International Planning Competition} (IPC). Moreover, it opens up a way towards \emph{bootstrapping} planning action models, enabling a planner to gradually learn/update its action model. Apart from these, our compilation exhibits the following contributions:
\begin{enumerate}
\item {\bf\em Input flexibility}. Our classical planning compilation is flexible to various amount and kind of available input knowledge. The action model to learn can be partially specified and the learning examples can range from a set of plans (with their corresponding initial state) or state observations, to just a set of initial and final states where no intermediate action or state is observed. % Also accepts background knowledge

\item {\bf\em Model validation}. The compilation poses a novel framework to assess the validation of a STRIPS model with respect to plan executions. This validation capacity goes beyond the functionality of VAL~\cite{howey2004val} since it does require neither a full action model nor a fully observed plan to determine validation. 
  
\item {\bf\em Model evaluation}. The compilation can assess how well a given \strips\ action model matches a plan execution, which allows us to assess learning performance without knowing the actual action model. The idea is to assess the amount of edition that is required by the input action model to induce the given observations of plan executions. 
\end{enumerate}

A first description of the compilation previously appeared in our previous conference paper~\cite{aineto2018learning}. Compared to that paper, this work includes the following novel material:
\begin{itemize}
\item A unified formulation for learning and evaluating \strips\ action models from observed executions of plans. Further, these executions can only comprise state observations.
\item A redefinition of the ML metrics {\em precision} and {\em recall} to evaluate \strips\ action models with respect to observations of plan executions.
%\item Leveraging diverse forms of {\em background knowledge} for learning and evaluating \strips\ action models.
\item A complete empirical evaluation of the compilation approach for learning of \strips\ action models. Our evaluation analyses how input knowledge affects to the performance of the compilation approach when learning and evaluating \strips\ action models. 
\end{itemize}

Section~\ref{sec:background} introduces classical planning and reviews related work on learning planning action models. Section~\ref{sec:motivation} motivates our compilation approach for learning of \strips\ action models from observations of plan executions. Section~\ref{sec:learning} introduces the \strips\ action model (the target of our learning and evaluation tasks) and formalizes the learning of \strips\ action models with regard to different amount and kind of available input knowledge. Sections~\ref{sec:Section5} and ~\ref{sec:Section6} describe our compilation approach for addressing the formalized learning tasks its extension to evaluate and recognize \strips\ action models. Section~\ref{sec:Section7} reports the data collected in a two-fold empirical evaluation of our learning approach: First, the learned \strips\ action models are tested with observations of plan executions and second, the learned models are compared to the actual models. Finally, Section ~\ref{sec:Section8} discusses the strengths and weaknesses of the compilation approach and proposes several opportunities for future research.

 
