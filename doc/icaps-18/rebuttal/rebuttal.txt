Reviewer1 suggested a comparison with the ARMS system. We thoughtful considered this in the composition of the paper but decided not to include it because: while the learning task addressed by ARMS is an optimization task (maximizing the number of covered examples) our learning task is a satisfying task, aims covering all the examples. The satisfying approach is relevant when learning examples are not noisy, e.g. when learning from video-games or simulators with full observability. As a matter of fact, the metric used in the ARMS AIJ paper is not informative in our case: the STRIPS models learned by our approach always cover all the learning examples (they would always report 0 errors). One can use a testing set but the particular results would depend on the content of this set. This is the reason why we evaluate our approach comparing the learned models with respect to a reference model and why we introduced the "Precision" and "Recall" metrics. Finally, we reported the results obtained with a fixed set of 5 problems because we wanted to asses how far a classical planner can get with such a limited amount of input knowledge. 

With respect to the comments of reviewer2. The classical planning instances that represent the learning examples belong to the same frame, (same fluents and actions, the actual examples are available at the anonymous repository https://github.com/anonsub/strips-learning). In the final version of the paper we will introduce an example describing how we serialize plans and step through each plan. Madagascar has shown to perform well in IPC domains populated with dead-ends such as the "floortile". We also did experiments with the FD planner but the obtained results where poorer often because of the preprocessing stages of this planner. 

We appreciate the comments on the learning bias suggested by the reviewer3 and we agree with him that our compilation favors extra preconditions but fewer effects since classical planners tend to minimize plan length. We plan to introduce this discussion in the final version of the paper. Our main motivation for using a classical planner for learning strips models was opening the door to the bootstrapping of planning action models, that is a planner generating its own experience and learn from them on it own the action model for a given domain. In addition, the practicality of the compilation approach allow us to easily report results over a wide range of domains (the ARMS AIJ paper reported results on 6 domains, Depots, Driverlog, Zenotravel, Satellite, Rover, and Freecell.

