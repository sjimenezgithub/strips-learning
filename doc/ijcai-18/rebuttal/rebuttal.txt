Rebuttal #1:
-------------
We sincerely thank reviewers for their constructive comments and criticisms which help to clarify details of our approach. Unlike extensive-data ML, our approach explores an alternative research direction to learn sound action models from a small amount of correct input data. Further, this is the first work that learns and evaluates action models exclusively using an off-the-shelf classical planner. We belief this result is relevant by itself because it opens up a way towards the bootstrapping of planning action models where a planner gradually learns/updates its action model. 

The SAT-based system ARMS is the closest system to compare with (also requires the operator heads). ARMS addresses however a different learning task: (1) learns from plan traces (the actions observations are assumed to be correct) while we learn from state observations (2), ARMS addresses an optimization task (i.e. maximizing the # of covered examples) while ours is a satisfying task, we compute a conservative model that is guaranteed to be applicable at ALL the given observations and (3), ARMS evaluates the quality of the learned models using two different functions "error rate" that evaluates the quality of the learned preconditions and "redundancy" that evaluates the quality of the positive effects. 

Rebuttal #2:
-------------
In effect a SAT-based compilation could also be used for the learning and evaluation tasks addressed in this paper.  We bet on classical planning because when there is an unknown # of missing observations, planning seems more natural than SAT because the planning horizon is no longer known and addressing these tasks is in our research agenda. Further, the planning commmunity has shown a tremendous experince in the develpment of informative while inexpensiver heuristic functions able to evaluate millions of symbolic states in seconds time. We believe that existing relaxations of the classical planning task, such as the "Relaxed plan" have an important role to play in the assessment of generative models with regard to large amounts of partially-observable/noisy examples. 

Like happens with satisfying planners, our approach is extensible to address the corresponding optimization task, e.g. in our case minimizing the # of model edits required to cover a set of partially-observable/noisy state observations. As a first step, this work aimed at understanding the grounds of the compilation for learning and evaluating STRIPS models in fully-observable environments (e.g. classical planning tasks, video-games, simulators) but extending this approach to partially-observable/noisy environments is definitely in agenda. 

Answering the reviewer questions:
1. We learn actions preconditions starting from the most specific hypothesis (all preconditions) just because we obtained better experimental results. 
2. We agree with the reviewer that the "one test_i fluent" is a more natural encoding. We plan to evaluate and chekc whether we achieve some performance gain. 


Rebuttal #3:
-------------
The contribution of our approach is leveraging classical planning not only for (1) LEARNING, that allows us to report quantitative results over a wide range of different domains (15 by the time being despite we are working to cover any IPC domain with the STRIPS requirement) but also for (2), EVALUATING how well a given STRIPS model matches a test set of observations.

Evaluating STRIPS models according to a test set of observations enables the "STRIPS model recognition" task. This is relevant because of the high expressiveness of STRIPS (as expressive as a Turing Machine with finite tape). Different generative models like policies, programs, grammars and different forms of domain-specific control knowledge are STRIPS compilable (see the series of work by Jorge Baier, Sheila McIlraith et al). With this regard, our work poses a general framework to assess how a given generative model (provided that it is STRIPS compilable) matches a test set of observations.


Rebuttal #4:
-------------
The evaluation focused on understanding which models can be learned from just 25 observations. Results revealed that 25 was not enough to learn action models in the domains with the largest # of schemas (this # ranges [1,7] in our evaluation). The largest this # the lowest chance an operator of being chosen (e.g. "disembark-truck" action is missing from the "driverlog" domain or "paint-down" is missing from "floortile"). Including more observations, specially of the missing actions, leads to better action models. Because our approach is a planning compilation, the limit on the # of observations is given by the planner performance. Current SAT-based planners have performance issues with planning horizons beyond 150-200 steps (since actions for programming preconditions/effects are often applied in parallel, in a single step, this means we can handle 50-80 input observations with a SAT-based planner.

Precision&Recall did not reach 1.0 in some domains with few schemes because learning "discovered" preconditions that were not specified in the IPC/reference domain. For instance, we learned the preconditions (connected ?place1 ?place2) and (connected ?place2 ?place1) for the "move" action in "visitall", while only (connected ?place1 ?place2) was specified in the IPC/reference model. 

The input observations affects to the quality of the learned models. Were are using one problem for each domain with a small # of objects because the compiled task is more tractable. If there is IPC instances small enough, we use an IPC instance, otherwise we created a small problem. An interesting research question is identifying which is the smallest # of objects per type required to learn a complete STRIPS action model for a given domain. This question has recently been addressed for Schematic Invariants (Schematic Invariants by Reduction to Ground Invariants, J. Rintanen IJCAI 2017). We believe that this research direction is promising to obtain similar results for learning STRIPS action models.
