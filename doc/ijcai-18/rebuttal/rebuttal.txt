Rebuttal #1:
-------------
Unlike extensive-data ML, this work explores an alternative research direction to learn sound models from small amounts of correct input data. Further, this is the first work on learning and evaluating STRIPS action models from state observations that report reproducible results over a wide range of domains exclusively using an off-the-shelf classical planner. We belief this approach is relevant by itself because opens up a way towards the bootstrapping of planning action models where a planner gradually learns/updates its action model.


Rebuttal #2:
-------------
We agree with the reviewer that a SAT-based compilation could be used for the addressed learning task. With this regard, the SAT-based system ARMS is the closest system to compare with (also requires the operator heads). ARMS  addresses however a different learning task: (1) learns from plan traces (the actions observations are assumed to be correct) while we learn from state observations and (2), ARMS addresses an optimization task (i.e. maximizing the number of covered examples) while ours is a satisfying task, we compute a conservative model that is guaranteed to be applicable at ALL the given observations.

Like happens with satisfying planners, our approach is extensible to address the corresponding optimization task, e.g. in our case minimizing the number of model edits required to cover a set of partially-observable/noisy state observations. This work aimed at understanding the grounds of the compilation for learning and evaluating STRIPS models in fully-observable environments (e.g. classical planning tasks, video-games, simulators) but extending this approach to partially-observable/noisy environments is in our research agenda. With this said, we bet on classical planning because we believe that existing relaxations of the classical planning task, such as the "Relaxed plan" have an important role to play in the assessment of generative models with regard to large amounts of partially-observable/noisy examples. Further, when there is an unknown number of missing observations, planning seems more natural than SAT because the planning horizon is no longer known.

Answering the reviewer questions:
1. We learn actions preconditions starting from the most specific hypothesis (all preconditions) because we obtained better experimental results (we attach the results we got when starting from the most general hypothesis (no preconditions). 
2. We agree with the reviewer that the "one test_i fluent" is a more natural encoding. We will evaluate it to see if we achieve some performance gain. 


Rebuttal #3:
-------------
The contribution of our approach is leveraging classical planning not only for (1) LEARNING, that allows us to report quantitative results over a wide range of different domains but also for (2), EVALUATING the quality of a STRIPS model with regard to a test set of observations.

Evaluating STRIPS models with a test set of observations enables the model recognition task. This is relevant because of the high expressiveness of STRIPS (as expressive as a Turing Machine with finite tape). Different generative models like policies, programs or grammars are STRIPS compilable (see the series of work by Jorge Baier, Sheila McIlraith et al). Therefore, this work poses a general method to assess how a given generative model matches a test set of observations: for a wide range of different generative models (the STRIPS compilable ones), and exclusively using classical planning. As far as we know, this is the first work on doing so.



Rebuttal #4:
-------------
The empirical evaluation focused on understanding which kind of STRIPS action models could be learned from just 25 state observations. The results revealed that 25 state observations were enough to learn action models with few action schemes,  (e.g "blocks" or "gripper"). In some of these domains ("hanoi", "visitall", "npuzzle") the reported Precision&Recall did not reach 1.0 for the preconditions. The reason is that learning discovered preconditions that were not specified in the actual/reference domain. For instance, our approach learned for the "move" action in the "visitall" the preconditions (connected ?place1 ?place2) and (connected ?place2 ?place1), while only the (connected ?place1 ?place2) precondition is present in the actual/reference model, despite both preconditions are actually correct. 

Learning accurate models from few examples becomes harder in domains with larger number of action schemes, in these cases the different actions have lower chances of being chosen. Examples are the "disembark-truck" action missing from the "driverlog" domain, the "paint-down" action missing from the "floortile" domain or the "move-curb-to-curb" from the "parking" domain. Including more examples, specially examples of these missing actions, definitely leads to better strips action models.

Because our approach is a classical planning compilation, the limit on the number of input observations is given by the limitation of the planner performance. In the particular case of current SAT-based planners, they are known to have performance issues with planning horizons beyond the 150-200 steps (this would currently limit our approach to about a hundred of input examples).

With this said, we agree with the reviewer that the set of input problems definitely affects to the quality of the learned models. Currently were are selecting problems for each domain with a small number of objects because they are easier to be solved and the result of the compilation is more tractable. An interesting research question is identifying which is the smallest number of objects per type required to learn a complete STRIPS action model for a given domain. This question has recently been addressed for Schematic Invariants (Schematic Invariants by Reduction to Ground Invariants, J. Rintanen IJCAI 2017). We believe that this research direction is promising to obtain similar results for learning STRIPS action models.
