\def\year{2017}\relax
%File: formatting-instruction.tex
\documentclass[letterpaper]{article} %DO NOT CHANGE THIS
\usepackage{aaai18}  %Required
\usepackage{times}  %Required
\usepackage{helvet}  %Required
\usepackage{courier}  %Required
\usepackage{url}  %Required
\usepackage{graphicx}  %Required
\frenchspacing  %Required
\setlength{\pdfpagewidth}{8.5in}  %Required
\setlength{\pdfpageheight}{11in}  %Required
%PDF Info Is Required:
  \pdfinfo{}
\setcounter{secnumdepth}{0}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{multirow}
\usepackage{tikz}
\usepackage{comment}

\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{listings}

\lstset{
  basicstyle=\ttfamily,
  mathescape
}


\usepackage{multicol}
\usepackage{arydshln}
\usetikzlibrary{calc,backgrounds,positioning,fit}


\newcommand{\tup}[1]{{\langle #1 \rangle}}

\newcommand{\pre}{\mathsf{pre}}     % precondition
\newcommand{\del}{\mathsf{del}}     % effect
\newcommand{\add}{\mathsf{add}}     % effect
\newcommand{\eff}{\mathsf{eff}}     % effect
\newcommand{\cond}{\mathsf{cond}}   % conditional effect
\newcommand{\true}{\mathsf{true}}   % true
\newcommand{\false}{\mathsf{false}} % false
\newcommand{\PE}{\mathrm{PE}}     % precondition
\newcommand{\strips}{\textsc{Strips}}     % precondition


\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{definition}[theorem]{Definition}


\begin{document}

\title{Planning Model Recognition}
\author{\#39}


% Commented for blind submission
\author{Diego Aineto\and Sergio Jim\'enez\and Eva Onaindia\\
{\small Departamento de Sistemas Inform\'aticos y Computaci\'on}\\
{\small Universitat Polit\`ecnica de Val\`encia.}\\
{\small Camino de Vera s/n. 46022 Valencia, Spain}\\
{\small \{dieaigar,serjice,onaindia\}@dsic.upv.es}}

\maketitle
\begin{abstract} 
This paper defines the {\em Planning Model Recognition} task. Given a set of possible planning models and an observation of a plan execution, {\em Planning Model Recognition} is the task of identifying which model has the highest probability of producing the given observation. The paper proposes a metric to assess the likelihood of a given \strips\ model to produce the observation of a plan execution and a method for computing this likelihood using classical planning. This metric is robust to missing intermediate states and actions in the input observation of a plan execution. The effectiveness of our method is empirically evaluated for solving the {\em planning model recognition} task when the set of possible \strips\ models represents different finite tape {\em Turing Machines} that share the same tape alphabet and the same set of machine states.
\end{abstract}


\section{Introduction}
\label{sec:section1}
{\em Plan recognition} is the task of predicting the future actions of an agent by observing its current behaviour. {\em Goal recognition} is a subtask of plan recognition with the particular objective of discovering the terminal goal of an agent given its behaviour. A large number of methods have been proposed for plan recognition: methods that include rule-based  systems,  parsing  (both  conventional  and  stochastic), graph-covering, Bayesian nets, \ldots. 

This paper defines {\em planning model recognition}, the task of identifying which model has the highest probability of producing the current behaviour of an agent. Despite related to both {\em Plan/Goal recognition}, this task is relevant because recognizing the followed model allows to apply the machinery of the crisp framework for {\em Plan recognition as planning} that leverages on a known planning model~\cite{ramirez2012plan,ramirez2009plan} besides, planning model recognition is also useful to determine whether the curent agent behaviour is optimal with respect to the most plausible model. 

The paper proposes a metric to assess the likelihood of a given \strips\ model to produce the observation of a plan execution and a method for computing this likelihood using classical planning. This metric is robust to missing intermediate states and actions in the input observation of a plan execution. The effectiveness of our method is empirically evaluated for solving {\em planning model recognition} tasks when the set of possible \strips\ models represents a set of different finite tape {\em Turing Machines} that share the same tape alphabet and the same set of machine states.


\section{Background}
\label{sec:section2}
This section defines the classical planning model that we follow in this work.

\subsection{Classical planning}
Our approach for learning CSGs is compiling this inductive learning task into a classical planning task.

We use $F$ to denote the set of {\em fluents} (propositional variables) describing a state. A {\em literal} $l$ is a valuation of a fluent $f\in F$; i.e. either~$l=f$ or $l=\neg f$. A set of literals $L$ represents a partial assignment of values to fluents (without loss of generality, we will assume that $L$ does not contain conflicting values). We use $\mathcal{L}(F)$ to denote the set of all literal sets on $F$; i.e.~all partial assignments of values to fluents.

A {\em state} $s$ is a full assignment of values to fluents; $|s|=|F|$, so the size of the state space is $2^{|F|}$. Explicitly including negative literals $\neg f$ in states simplifies subsequent definitions but often we will abuse of notation by defining a state $s$ only in terms of the fluents that are true in $s$, as it is common in \strips\ planning.

A {\em classical planning frame} is a tuple $\Phi=\tup{F,A}$, where $F$ is a set of fluents and $A$ is a set of actions. An action $a\in A$ is defined with {\em preconditions}, $\pre(a)\subseteq\mathcal{L}(F)$, {\em positive effects}, $\eff^+(a)\subseteq\mathcal{L}(F)$, and {\em negative effects} $\eff^-(a)\subseteq\mathcal{L}(F)$. We say that an action $a\in A$ is {\em applicable} in a state $s$ iff $\pre(a)\subseteq s$. The result of applying $a$ in $s$ is the {\em successor state} denoted by $\theta(s,a)=\{s\setminus\eff^-(a))\cup\eff^+(a)\}$.

The result of applying action $a$ in state $s$ is the {\em successor} state $\theta(s,a)=\{s\setminus\eff_c^-(s,a))\cup\eff_c^+(s,a)\}$ where $\eff_c^-(s,a)\subseteq triggered(s,a)$ and $\eff_c^+(s,a)\subseteq triggered(s,a)$ are, respectively, the triggered {\em negative} and {\em positive} effects.

A {\em classical planning problem} is a tuple $P=\tup{F,A,I,G}$, where $I$ is an initial state and $G\subseteq\mathcal{L}(F)$ is a goal condition. A {\em plan} for $P$ is an action sequence $\pi=\tup{a_1, \ldots, a_n}$ that induces the {\em state trajectory} $\tup{s_0, s_1, \ldots, s_n}$ such that $s_0=I$ and $a_i$ ({\small $1\leq i\leq n$}) is applicable in $s_{i-1}$ and generates the successor state $s_i=\theta(s_{i-1},a_i)$. The {\em plan length} is denoted with $|\pi|=n$ . A plan $\pi$ {\em solves} $P$ iff $G\subseteq s_n$; i.e.~if the goal condition is satisfied in the last state resulting from the application of the plan $\pi$ in the initial state $I$.

\subsection{\strips\ action schemas}
This work addresses the recognition of PDDL action schemas that follow the \strips\ requirement~\cite{mcdermott1998pddl,fox2003pddl2}. Figure~\ref{fig:stack} shows the {\em stack} action schema, coded in PDDL, from a four-operator {\em blocksworld}~\cite{slaney2001blocks}.

\begin{figure}[hbt!]
\begin{scriptsize}
\begin{verbatim}
(:action stack
 :parameters (?v1 ?v2 - object)
 :precondition (and (holding ?v1) (clear ?v2))
 :effect (and (not (holding ?v1)) (not (clear ?v2)) 
              (handempty) (clear ?v1) (on ?v1 ?v2)))
\end{verbatim}
\end{scriptsize}
 \caption{\small \strips\ operator schema coding, in PDDL, the {\em stack} action from a four-operator {\em blocksworld}.}
\label{fig:stack}
\end{figure}

We assume that fluents $F$ are instantiated from a set of {\em predicates} $\Psi$, as in PDDL. Each predicate $p\in\Psi$ has an argument list of arity $ar(p)$. Given a set of {\em objects} $\Omega$, the set of fluents $F$ is induced by assigning objects in $\Omega$ to the arguments of predicates in $\Psi$, i.e.~$F=\{p(\omega):p\in\Psi,\omega\in\Omega^{ar(p)}\}$ s.t. $\Omega^k$ is the $k$-th Cartesian power of $\Omega$.

Let $\Omega_v=\{v_i\}_{i=1}^{\operatorname*{max}_{a\in A} ar(a)}$ be a new set of objects ($\Omega\cap\Omega_v=\emptyset$), denoted as {\em variable names}, and that is bound by the maximum arity of an action in a given planning frame. For instance, in a three-block {\em blocksworld} $\Omega=\{block_1, block_2, block_3\}$ while $\Omega_v=\{v_1, v_2\}$ because the operators with the maximum arity, {\small\tt stack} and {\small\tt unstack}, have arity two. We define $F_v$, a new set of fluents s.t. $F\cap F_v=\emptyset$, that results from instantiating $\Psi$ using only the objects in $\Omega_v$, i.e. the variable names, and that defines the elements that can appear in an action schema. In {\em blocksworld} this set contains 11 elements, $F_v$={\small\tt\{handempty, holding($v_1$), holding($v_2$), clear($v_1$), clear($v_2$), ontable($v_1$), ontable($v_2$), on($v_1,v_1$), on($v_1,v_2$), on($v_2,v_1$), on($v_2,v_2$)\}}.

For a given operator schema $\xi$, we define $F_v(\xi)\subseteq F_v$ as the subset of fluents that represent the elements that can appear in that action schema. For instance, for the {\em stack} action schema $F_v({\tt stack})=F_v$ while $F_v({\tt pickup})$={\small\tt\{handempty, holding($v_1$), clear($v_1$), ontable($v_1$), on($v_1,v_1$)\}} excludes the fluents from $F_v$ that involve $v_2$ because the action header {\small\tt pickup($v_1$)} contains the single parameter $v_1$.

We assume also that actions $a\in A$ are instantiated from \strips\ operator schemas $\xi=\tup{head(\xi),pre(\xi),add(\xi),del(\xi)}$ where:
\begin{itemize}
\item $head(\xi)=\tup{name(\xi),pars(\xi)}$, is the operator {\em header} defined by its name and the corresponding {\em variable names}, $pars(\xi)=\{v_i\}_{i=1}^{ar(\xi)}$. The headers of a four-operator {\em blocksworld} are {\small\tt pickup($v_1$), putdown($v_1$), stack($v_1,v_2$)} and {\small\tt unstack($v_1,v_2$)}.
\item The preconditions $pre(\xi)\subseteq F_v$, the negative effects $del(\xi)\subseteq F_v$, and the positive effects $add(\xi)\subseteq F_v$ such that, $del(\xi)\subseteq pre(\xi)$, $del(\xi)\cap add(\xi)=\emptyset$ and $pre(\xi)\cap add(\xi)=\emptyset$.
\end{itemize}
Given the set of predicates $\Psi$ and the header of the operator schema $\xi$, $2^{2|F_v(\xi)|}$ defines the size of the space of possible \strips\ models for that operator. Note that the previous constraints require that negative effects appear as preconditions and that they cannot be positive effects and also, that a positive effect cannot appear as a precondition. For instance, $2^{2|F_v(stack)|}=4194304$ for the blocksworld {\tt stack} operator while for {\tt pickup} is only 1024.

Last but not least, we say that two \strips\ operator schemes $\xi$ and $\xi'$ are {\em comparable} if both schemas have the same parameters so they share the same space of possible \strips\ models. Formally, if $pars(\xi)=pars(\xi')$ it also holds that $F_v(\xi)=F_v(\xi')$. For instance, we can claim that blocksworld operators {\tt stack} and {\tt unstack} are {\em comparable} while  {\tt stack} and {\tt pickup} are not. Two \strips\ action models $\mathcal{M}$ and $\mathcal{M}'$ are {\em comparable} iff there exists a bijective function $\mathcal{M} \mapsto \mathcal{M}^*$ that maps every $\xi\in\mathcal{M}$ to a comparable action schema $\xi'\in\mathcal{M'}$ and viceversa.



\section{Planning Model Recognition}
\label{sec:section4}
Given a set of possible action models $M=\{\mathcal{M}_1,\ldots,\mathcal{M}_m\}$ and an observation of a plan execution $\mathcal{T}=\tup{s_0,a,_1,s_1,\ldots,a_n,s_{n}}$ obtained watching the execution of a plan $\pi=\tup{a_1, \ldots, a_n}$ such that, for each {\small $1\leq i\leq n$}, $a_i$ is applicable in $s_{i-1}$ and generates the successor state $s_i=\theta(s_{i-1},a_i)$. {\em Planning Model Recognition} is the task of identifying which model $\mathcal{M}\in M$ has the highest probability of producing the given observations $\mathcal{T}$.

\subsection{The \strips\ edit distance}
The intuition of our method for {\em Planning Model Recognition} is to assess how well an action model explains a given observations of plan executions according to the amount of {\em edition} required by the model to induce that observations. We first define the two allowed \emph{operations} to edit a given \strips\ action model $\mathcal{M}$:
\begin{itemize}
\item {\em Deletion}. A fluent $pre_f(\xi)/del_f(\xi)/add_f(\xi)$ is removed from the operator schema $\xi\in\mathcal{M}$, such that $f\in F_v(\xi)$.
\item {\em Insertion}. A fluent $pre_f(\xi)/del_f(\xi)/add_f(\xi)$ is added to the operator schema $\xi\in\mathcal{M}$, s.t. $f\in F_v(\xi)$.
\end{itemize}

We can now formalize an {\em edit distance} that quantifies how similar two given \strips\ action models are. The distance is symmetric and meets the {\em metric axioms} provided that the two {\em edit operations}, deletion and insertion, have the same positive cost.

\begin{definition}
  Let $\mathcal{M}$ and $\mathcal{M}'$ be two \strips\ action models, such that they are {\em comparable}. The {\bf edit distance}, denoted as $\delta(\mathcal{M},\mathcal{M}')$, is the minimum number of {\em edit operations} that is required to transform $\mathcal{M}$ into $\mathcal{M}'$.
\end{definition}

Since $F_v$ is a bound set, the maximum number of edits that can be introduced to a given action model defined within $F_v$ is bound as well. In more detail, for an operator schema $\xi\in\mathcal{M}$ the maximum number of edits that can be introduced to their precondition set is $|F_v(\xi)|$ while the max number of edits that can be introduced to the effects is twice $|F_v(\xi)|$.
\begin{definition}
The \textbf{maximum edit distance} of an \strips\ action model $\mathcal{M}$ built from the set of possible elements $F_v$ is $\delta(\mathcal{M},*)=\sum_{\xi\in\mathcal{M}} 3\times|F_v(\xi)|$.
\end{definition}

We define now an edit distance to asses the mathing of a learned action model with respect to a plan trace $\mathcal{T}$. 

\begin{definition}
  Given $\mathcal{M}$, a \strips\ action model built from $F_v$, and a plan trace $\mathcal{T}$ whose state observation are built with fluents in $F$. The {\bf observation edit distance}, denoted by  $\delta(\mathcal{M},\mathcal{T})$, is the minimal edit distance from $\mathcal{M}$ to any {\em comparable} model $\mathcal{M}'$, such that $\mathcal{M}'$ can produce a valid plan trace $\mathcal{T}$; \[\delta(\mathcal{M},\mathcal{T})=\min_{\forall \mathcal{M}' \rightarrow \mathcal{T}} \delta(\mathcal{M},\mathcal{M}')\]
\end{definition}

Note that the distance of an action model $\mathcal{M}$ with respect to a plan trace $\mathcal{T}$ could also be defined quantifying the amount of edition required by the observations of the plan execution to match the given model. This would imply defining {\em edit operations} that modify the fluents in the state observations instead of the {\em edit operations} that modify the action schemes~\cite{sohrabi:precognition:IJCAI2016}. Our definition of the {\em observation edit distance} is more practical since normally, $F_v$ is smaller than $F$ because the number of {\em variable objects} is smaller than the number of objects in the state observations.

\subsection{From edit distances into posterior probabilities}
The {\em observation edit distance} is mappable into a likelihood with the following expression $1-\frac{\delta(\mathcal{M},\mathcal{O})}{\delta(\mathcal{M},*)}$. According to the Bayes rule, the probability of an hypothesis $\mathcal{H}$ given the observations $\mathcal{O}$ can be computed with $P(\mathcal{H}|\mathcal{O})=\frac{P(\mathcal{O}|\mathcal{H})P(\mathcal{H})}{P(\mathcal{O})}$. In our scenario, the hypotheses are about the set of possible \strips\ action models. Given set of predicates $\Psi$ and a given a set of operator headers (in other words, given the $F_v(\xi)$ sets) the size of the set of possible \strips\ models set is $\prod_\xi 2^{2|F_v(\xi)|}$, as explained in Section~\ref{sec:Section3}. With respect to the observations, given $\Psi$ and a set of objects $\Omega$, the size of the possible state observations of length $n$, that is $\mathcal{O}=s_0,\ldots,s_n$ is given by $2^{n\times|F|}$.

With this regard, $P(\mathcal{M}|\mathcal{O})$, the probability distribution of the possible \strips\ models (within the $F_v(\xi)$ sets) given an observation sequence $\mathcal{O}$ could be computed by:
\begin{enumerate}
\item Computing the {\em observation edit distance} $\delta(\mathcal{M},\mathcal{O})$ for every possible model $\mathcal{M}$. If a set of plans $\Pi$ is available, this same strategy can be followed using the {\em plan edit distance} $\delta(\mathcal{M},\Pi)$.
\item Applying the resulting distances to the above $P(\mathcal{O}|\mathcal{M})$ formula to map these distances into likelihoods
\item Applying the Bayes rule to obtain the normalized posterior probabilities, these probabilities must sum 1.
\end{enumerate}


\section{Computing the edit distance with classical planning}
Our compilation is extensible to compute the {\em observation edit distance} by simply considering that the input \strips\ model $\mathcal{M}$, given in a learning task $\Lambda=\tup{\mathcal{M},\Psi,\mathcal{T}}$, is {\em non-empty}. In other words, now $\mathcal{M}$ is a set of given operator schemas, wherein each $\xi\in\mathcal{M}$ initially contains $head(\xi)$ but also the $pre(\xi)$, $del(\xi)$ and $add(\xi)$ sets. A solution to the planning task resulting from the extended compilation is a sequence of actions that:

\begin{enumerate}
\item {\bf Edits the action model $\mathcal{M}$ to build $\mathcal{M}'$}. A solution plan starts with a {\em prefix} that modifies the preconditions and effects of the action schemes in $\mathcal{M}$ using to the two {\em edit operations} defined above, {\em deletion} and {\em insertion}. In theory, we could implement a third edit operation for {\em substituting} a fluent from a given operator schema. However, and with the aim of keeping a tractable branching factor of the planning instances that result from our compilations, we only implement {\em deletion} and {\em insertion}.
\item {\bf Validates the edited model $\mathcal{M}'$ in the observed plan trace}. The solution plan continues with a postfix that validates the edited model $\mathcal{M}'$ on the given observations $\mathcal{T}$, as explained in Section~\ref{sec:Section5} for the models that are programmed from scratch.
\end{enumerate}

Now $\Lambda$ does not formalize a learning task but the task of editing $\mathcal{M}$ to produce the plan trace $\mathcal{T}$, which results in the edited model $\mathcal{M}'$. The output of the extended compilation is a classical planning task $P_{\Lambda}'=\tup{F_{\Lambda},A_{\Lambda}',I_{\Lambda}',G_{\Lambda}}$:

\begin{itemize}
\item $F_{\Lambda}$ and $G_{\Lambda}$ are defined as in the previous compilation.
\item $I_{\Lambda}'$ contains the fluents from $F$ that encode $s_0$ and $mode_{prog}$ set to true. In addition, the input action model $\mathcal{M}$ is now encoded in the initial state. This means that the fluents $pre_f(\xi)/del_f(\xi)/add_f(\xi)$, $f\in F_v(\xi)$, hold in the initial state iff they appear in $\mathcal{M}$.
\item $A_{\Lambda}'$, comprises the same three kinds of actions of $A_{\Lambda}$. The actions for {\em applying} an already programmed operator schema and the actions for {\em validating} an observation are defined exactly as in the previous compilation. The only difference here is that the actions for {\em programming} the operator schema now implement the two {\em edit operations} (i.e. include actions for {\em inserting} a precondition and for {\em deleting} a negative/positive effect).
\end{itemize}

To illustrate this, the plan of Figure~\ref{fig:plan-pdistance} shows the plan for editing a given {\em blockswold} action model where again the positive effects {\tt\small (handempty)} and {\tt\small (clear ?v1)} of the {\tt\small stack} schema are missing. In this case the edited action model is however validated at the plan shown in Figure~\ref{fig:example-plans}.

\begin{figure}[hbt!]
{\tt\small
00 : (insert\_add\_handempty\_stack)\\
01 : (insert\_add\_clear\_stack\_var1)\\
02 : (apply\_unstack blockB blockA i1 i2)\\
03 : (apply\_putdown blockB i2 i3)\\
04 : (apply\_pickup blockA i3 i4)\\
05 : (apply\_stack blockA blockB i4 i5)\\
06 : (validate\_1)
}
 \caption{\small Plan for editing a given {\em blockswold} schema and validating it at the plan shown in Figure~\ref{fig:example-plans}.}
\label{fig:plan-pdistance}
\end{figure}

Our interest when computing the {\em observation edit distance} is not in the resulting action model $\mathcal{M}'$ but in the number of required {\em edit operations} (insertions and deleitions) for that $\mathcal{M}'$ is validated in the given observations, e.g. $\delta(\mathcal{M},\mathcal{T})=2$ for the example in Figure~\ref{fig:plan-pdistance}. In this case $\delta(\mathcal{M},*)=3\times 2\times (11+5)$ since there are 4 action schemes ({\small\tt pickup}, {\small\tt putdown}, {\small\tt stack} and {\small\tt unstack}) and $|F_v|=|F_v(stack)|=|F_v(unstack)|=11$ while $|F_v(pickup)|=|F_v(putdown)|=5$  (as shown in Section~\ref{sec:Section3}). The {\em observation edit distance} is exactly computed if the classical planning task resulting from our compilation is optimally solved (according to the number of edit actions); is approximated if it is solved with a satisfying planner; and is a less accurate estimate (but faster to be computed) if the solved task is a relaxation of the classical planning task that results from our compilation~\cite{bonet2001planning}.


\subsection{Experiments}
\label{sec:section5}
To evaluate the empirical performance of our method for {\em planning model recognition} we defined a set of possible \strips\ models that represents a set of different finite tape {\em Turing Machines} that share the same tape alphabet and the same set of machine states.

\subsection{Turing Machines as \strips\ models}
A {\em Turing machine} is a tuple $M=\tup{Q,q_o,Q_{\bot},\mathcal{T},\square,\Sigma,\delta}$:
\begin{itemize}
\item $Q$, is a finite and non-empty set of machine states such that $q_0\in Q$ is the initial state of the machine and $Q_{\bot}\subseteq Q$ is the subset of acceptor states.  
\item $\mathcal{T}$ is the {\em tape alphabet}, that is a finite non-empty set of symbols that includes the {\em blank symbol} $\square\in\mathcal{T}$ (the only symbol allowed to occur on the tape infinitely often) and that contains $\Sigma\subseteq\mathcal{T}$, the set of symbols allowed to initially appear in the tape (also called the {\em input alphabet}).
\item $\delta: (Q\setminus Q_{\bot})\times \mathcal{T}\rightarrow Q\times\{left,right\}\times \mathcal{T}$ is the {\em transition function}. If $\delta$ is not defined for the current pair of machine state and tape symbol, then the machine halts.
\end{itemize}

A table is the most common convention to represent the transitions defined by $\delta$, where the table rows are indexed by the current tape symbol, while the table columns are indexed by the current machine state. For each possible pair of tape symbol and machine state, there is a table entry that defines: (1) the tape symbol to print at the current position of the header (2) whether the header is shifted {\em left} or {\em right} after the print operation and (3), the new state of the machine after the print operation. For instance, Figure~\ref{tab:tm-anbncn} shows the table that represents the $\delta$ function of a {\em Turing Machine} for recognizing the $\{a^nb^nc^n : n \geq 1 \}$ language. In this example the tape alphabet is $\Sigma=\{a,b,c,x,y,z,\square\}$ while the possible machine states are $Q=\{q_0,q_1,q_2,q_3,q_4,\underline{q_5}\}$ where \underline{$q_5$} is the only acceptor state.

\begin{figure}
\begin{center}
    \begin{tabular}{| c | c | c | c | c | c | c |}
    \hline
      & $q_0$ & $q_1$ & $q_2$ & $q_3$ & $q_4$ & \underline{$q_5$} \\ \hline
    a & x,r,$q_1$ & a,r,$q_1$ & - &  a,l,$q_3$ & - & - \\ \hline
    b & - & y,r,$q_2$ & b,r,$q_2$ & b,l,$q_3$ & - & - \\ \hline
    c & - & - & z,l,$q_3$ & - & - & - \\ \hline
    x & - & - & - & x,r,$q_0$ & - & - \\ \hline
    y & y,r,$q_4$ & y,r,$q_1$ & - & y,l,$q_3$ & y,r,$q_4$ & - \\ \hline
    z & - & - & z,r,$q_2$ & z,l,$q_3$ & z,r,$q_4$ & - \\\hline
    $\square$ & - & - & - & - & $\square$,r,$q_5$  & - \\                
    \hline
    \end{tabular}
\end{center}
  \caption{\small Example of a seven-symbol six-state {\em Turing Machine} for recognizing the $\{a^nb^nc^n : n \geq 1 \}$ language (\underline{$q_5$} is the only acceptor state).}
  \label{tab:tm-anbncn}
\end{figure}

A classical planning frame $\Phi=\tup{F,A}$ encodes the {\em transition function} $\delta$ of a {\em Turing Machine} $M$ as follows. We assume that fluents $F$ are instantiated from a set of {\em predicates} $\Psi$, as in PDDL~\cite{fox2003pddl2}. Each predicate $p\in\Psi$ has an argument list of arity $ar(p)$. Given a set of {\em objects} $\Omega$ that represent the cells in the tape of the given Turing Machine $M$, the set of fluents $F$ is induced by assigning objects in $\Omega$ to the arguments of the predicates in $\Psi$; i.e.~$F=\{p(\omega):p\in\Psi,\omega\in\Omega^{ar(p)}\}$, where $\Omega^k$ is the $k$-th Cartesian power of $\Omega$. The predicates in $\Psi$ are:
\begin{itemize}
\item {\tt (head ?x)} that encodes the current position of the header in the tape.
\item {\tt (next ?x1 ?x2)} encoding that the cell {\tt ?x2} follows cell {\tt ?x1} in the tape.
\item {\tt (symbol-$\sigma$ ?x)} encoding that the tape cell {\tt ?x} contains the symbol $\sigma\in\Sigma$.
\item {\tt (state-$q$)} encoding that $q\in Q$ is the current machine state.
\end{itemize}

Likewise we assume that actions $a\in A$ are instantiated from \strips\ operator schema. For each transition in $\delta$, a \strips\ action schema is defined such that:
\begin{itemize}
\item The {\bf header} of the schema is {\tt transition-id(?xl ?x ?xr)} where $id$ uniquely identifies the transition in $\delta$ and the parameters $?xl$, $?x$ and $?xr$ are tape cells.
\item The {\bf precoditions} of the schema includes {\tt(head ?x)} and {\tt (next ?xl ?x) (next ?x ?xr)} to force that $?x$ is the tape cell currently pointed by the header and that $?xl$ and $?xr$ respectively are its left and right neighbours. Additionally the schema includes preconditions {\tt(symbol-$\sigma$ ?x)} and {\tt (state-$q$)} to capture the symbol pointed by the header and the currrent machine state.
\item The {\bf delete effects} remove the symbol pointed by the header and the currrent machine state while the {\bf positive effects} set the new symbol pointed by the header and the new machine state.
\end{itemize}

The \strips\ action schema of Figure~\ref{fig:update-rule} models the rule $a,q_0\rightarrow x,r,q_1$ of the Turing Machine defined in Figure~\ref{tab:tm-anbncn}. The full encoding of the Turing Machine defined in Figure~\ref{tab:tm-anbncn} produces a total of sixteen \strips\ action schema with the same structure as the one of Figure~\ref{fig:update-rule}. 
\begin{figure}[hbt!]
\begin{scriptsize}
\begin{lstlisting}
(:action transition-1 ;; a,$q_0\rightarrow$ x,r,$q_1$
  :parameters (?xl ?x ?xr)
  :precondition (and (head ?x)                       
                     (symbol-a ?x) (state-$q_0$)
                     (next ?xl ?x) (next ?x ?xr))
  :effect (and (not (head ?x)) 
               (not (symbol-a ?x)) (not (state-$q_0$))
               (head ?xr) (symbol-x ?x) (state-$q_1$)))
\end{lstlisting}
\end{scriptsize}
 \caption{\small \strips\ action schema that models the transition $a,q_0\rightarrow x,r,q_1$ of the Turing Machine defined in Figure~\ref{tab:tm-anbncn}.}
\label{fig:update-rule}
\end{figure}

The execution of a {\em Turing Machine} can then be defined as a {\em plan trace} $\mathcal{T}=\tup{s_0,a_1,s_1,\ldots,a_n,s_n}$ such that $s_0$ encodes the initial state of the tape plus the initial machine state and, for each {\small $1\leq i\leq n$}, $a_i$ is applicable in $s_{i-1}$ and generates the successor state $s_i=\theta(s_{i-1},a_i)$. 

\subsection{Related work}
\label{sec:section6}

\subsection{Conclussions}
\label{sec:section7}

\bibliographystyle{aaai}
\bibliography{planlearnbibliography}

\end{document}
